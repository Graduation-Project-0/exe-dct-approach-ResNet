{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b235e93d",
   "metadata": {},
   "source": [
    "# Malware Detection using ResNet - Full Training Notebook\n",
    "\n",
    "This notebook contains the complete pipeline for training a ResNet model to detect malware from executable files using image-based representations.\n",
    "\n",
    "**Image Channels:**\n",
    "- Channel 0: Sparse bigram frequency image\n",
    "- Channel 1: DCT-transformed bigram image  \n",
    "- Channel 2: Byteplot image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737ffadf",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b3b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    roc_curve, \n",
    "    auc, \n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "from typing import Dict, Tuple, Optional\n",
    "from scipy.fft import dctn\n",
    "from scipy.ndimage import zoom\n",
    "import math\n",
    "from torchvision import models\n",
    "\n",
    "sys.path.insert(0, os.path.dirname(os.path.abspath(os.getcwd())))\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e1e0a",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df9092",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "TRAIN_SPLIT = 0.7\n",
    "VAL_SPLIT = 0.2\n",
    "TEST_SPLIT = 0.1\n",
    "MAX_SAMPLES = None  # Set to integer to limit samples, None for all data\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "RESNET_VARIANT = 'resnet50'  # 'resnet18' or 'resnet50'\n",
    "PRETRAINED = True\n",
    "FREEZE_BACKBONE = False\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 25\n",
    "LEARNING_RATE = 0.001\n",
    "PATIENCE = 10\n",
    "USE_AMP = True  # Automatic Mixed Precision\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "\n",
    "NUM_WORKERS = 4\n",
    "PREFETCH_FACTOR = 2\n",
    "PERSISTENT_WORKERS = True\n",
    "\n",
    "CHECKPOINT_DIR = '../checkpoints'\n",
    "RESULTS_DIR = '../results'\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5727fc14",
   "metadata": {},
   "source": [
    "## 3. Image Generation Functions\n",
    "\n",
    "Functions to convert binary executables into image representations:\n",
    "- **Bigram Frequency Image**: 256x256 image from byte pair frequencies\n",
    "- **DCT Image**: DCT transform of the bigram image\n",
    "- **Byteplot Image**: Raw bytes resized to 256x256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e266bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_binary_file(file_path: str) -> bytes:\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def extract_bigrams(byte_data: bytes) -> np.ndarray:\n",
    "    bigram_freq = np.zeros(65536, dtype=np.float64)\n",
    "    \n",
    "    for i in range(len(byte_data) - 1):\n",
    "        bigram = (byte_data[i] << 8) | byte_data[i + 1]\n",
    "        bigram_freq[bigram] += 1\n",
    "    \n",
    "    return bigram_freq\n",
    "\n",
    "\n",
    "def create_bigram_image(bigram_freq: np.ndarray, zero_out_0000: bool = True) -> np.ndarray:\n",
    "    freq = bigram_freq.copy()\n",
    "    \n",
    "    if zero_out_0000:\n",
    "        freq[0] = 0\n",
    "    \n",
    "    total = np.sum(freq)\n",
    "    if total > 0:\n",
    "        freq = freq / total\n",
    "                  \n",
    "    bigram_image = freq.reshape(256, 256)\n",
    "    \n",
    "    return bigram_image\n",
    "\n",
    "\n",
    "def apply_2d_dct(image: np.ndarray) -> np.ndarray:\n",
    "    dct_image = dctn(image, type=2, norm='ortho')\n",
    "    \n",
    "    dct_image = np.abs(dct_image)\n",
    "    max_val = np.max(dct_image)\n",
    "    if max_val > 0:\n",
    "        dct_image = dct_image / max_val\n",
    "    \n",
    "    return dct_image\n",
    "\n",
    "\n",
    "def resize_image(image: np.ndarray, target_size: Tuple[int, int]) -> np.ndarray:\n",
    "    h, w = image.shape\n",
    "    target_h, target_w = target_size\n",
    "    \n",
    "    zoom_factors = (target_h / h, target_w / w)\n",
    "    resized = zoom(image, zoom_factors, order=1)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "def create_byteplot_from_bytes(byte_data: bytes, target_size: Tuple[int, int] = (256, 256)) -> np.ndarray:\n",
    "    byte_array = np.frombuffer(byte_data, dtype=np.uint8)\n",
    "    \n",
    "    total_bytes = len(byte_array)\n",
    "    side_length = int(math.sqrt(total_bytes))\n",
    "    \n",
    "    truncated_length = side_length * side_length\n",
    "    byte_array = byte_array[:truncated_length]\n",
    "    \n",
    "    byteplot = byte_array.reshape(side_length, side_length)\n",
    "    \n",
    "    byteplot_resized = resize_image(byteplot, target_size)\n",
    "    \n",
    "    byteplot_resized = byteplot_resized.astype(np.float32) / 255.0\n",
    "    \n",
    "    return byteplot_resized\n",
    "\n",
    "\n",
    "def create_three_channel_image(file_path: str) -> np.ndarray:\n",
    "    byte_data = read_binary_file(file_path)\n",
    "    \n",
    "    bigram_freq = extract_bigrams(byte_data)\n",
    "    \n",
    "    # Channel 0: Sparse bigram frequency image\n",
    "    # - Zero out 0000 bigram, normalize, reshape to 256x256\n",
    "    sparse_bigram = create_bigram_image(bigram_freq, zero_out_0000=True)\n",
    "    \n",
    "    # Channel 1: Bigram-DCT image (the main feature from the paper)\n",
    "    # - Apply full-frame DCT to de-sparsify and create distinctive patterns\n",
    "    dct_bigram = apply_2d_dct(sparse_bigram)\n",
    "    \n",
    "    # Channel 2: Byteplot image\n",
    "    # - Raw bytes as 2D visualization, resized to 256x256\n",
    "    byteplot = create_byteplot_from_bytes(byte_data, target_size=(256, 256))\n",
    "    \n",
    "    # Stack into 3 channels: [sparse_bigram, bigram_dct, byteplot]\n",
    "    three_channel = np.stack([sparse_bigram, dct_bigram, byteplot], axis=0)\n",
    "    \n",
    "    return three_channel.astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"Image generation functions defined!\")\n",
    "print(\"\\nPipeline summary (per paper):\")\n",
    "print(\"  1. Binary → Overlapping bigrams (e.g., 0a1bc48a → 0a1b, 1bc4, c48a)\")\n",
    "print(\"  2. Bigram frequency count → 256x256 sparse image (zero out 0000, normalize)\")\n",
    "print(\"  3. DCT transform → De-sparsified 'bigram-dct' image with textured patterns\")\n",
    "print(\"  4. Byteplot → Raw bytes as 256x256 image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078515bb",
   "metadata": {},
   "source": [
    "## 4. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662188b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareImageDataset(Dataset):\n",
    "    \"\"\"Dataset for malware detection using image representations of executables.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data_dir: str, \n",
    "        max_samples: Optional[int] = None\n",
    "    ):\n",
    "        self.data_dir = data_dir\n",
    "        self.samples = []  # List of (file_path, label)\n",
    "        self._load_samples(max_samples)\n",
    "    \n",
    "    def _load_samples(self, max_samples: Optional[int]):\n",
    "        \"\"\"Load sample file paths and labels.\"\"\"\n",
    "        malware_dir = os.path.join(self.data_dir, 'malware')\n",
    "        benign_dir = os.path.join(self.data_dir, 'benign')\n",
    "        \n",
    "        # Load malware samples (label = 1)\n",
    "        if os.path.exists(malware_dir):\n",
    "            for filename in os.listdir(malware_dir):\n",
    "                file_path = os.path.join(malware_dir, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    self.samples.append((file_path, 1))\n",
    "        \n",
    "        # Load benign samples (label = 0)\n",
    "        if os.path.exists(benign_dir):\n",
    "            for filename in os.listdir(benign_dir):\n",
    "                file_path = os.path.join(benign_dir, filename)\n",
    "                if os.path.isfile(file_path):\n",
    "                    self.samples.append((file_path, 0))\n",
    "        \n",
    "        # Shuffle samples\n",
    "        random.shuffle(self.samples)\n",
    "        \n",
    "        # Limit samples if specified\n",
    "        if max_samples is not None:\n",
    "            self.samples = self.samples[:max_samples]\n",
    "        \n",
    "        # Print statistics\n",
    "        malware_count = sum(1 for _, label in self.samples if label == 1)\n",
    "        benign_count = len(self.samples) - malware_count\n",
    "        print(f\"Loaded {len(self.samples)} samples:\")\n",
    "        print(f\"  Malware: {malware_count}\")\n",
    "        print(f\"  Benign:  {benign_count}\")\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        file_path, label = self.samples[idx]\n",
    "        \n",
    "        try:\n",
    "            # Create 3-channel image\n",
    "            image = create_three_channel_image(file_path)\n",
    "            image_tensor = torch.from_numpy(image).float()\n",
    "            return image_tensor, label\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            # Return zero tensor on error\n",
    "            image_tensor = torch.zeros((3, 256, 256), dtype=torch.float32)\n",
    "            return image_tensor, label\n",
    "\n",
    "\n",
    "def create_data_loaders(\n",
    "    data_dir: str,\n",
    "    batch_size: int = 32,\n",
    "    train_split: float = 0.7,\n",
    "    val_split: float = 0.2,\n",
    "    test_split: float = 0.1,\n",
    "    max_samples: Optional[int] = None,\n",
    "    num_workers: int = 0,\n",
    "    prefetch_factor: Optional[int] = None,\n",
    "    persistent_workers: bool = False\n",
    ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"Create train, validation, and test data loaders.\"\"\"\n",
    "    \n",
    "    full_dataset = MalwareImageDataset(data_dir, max_samples=max_samples)\n",
    "    \n",
    "    total_size = len(full_dataset)\n",
    "    train_size = int(train_split * total_size)\n",
    "    val_size = int(val_split * total_size)\n",
    "    test_size = total_size - train_size - val_size\n",
    "    \n",
    "    print(f\"\\nDataset splits:\")\n",
    "    print(f\"  Train: {train_size} ({train_split*100:.0f}%)\")\n",
    "    print(f\"  Val:   {val_size} ({val_split*100:.0f}%)\")\n",
    "    print(f\"  Test:  {test_size} ({test_split*100:.0f}%)\")\n",
    "    \n",
    "    # Split dataset\n",
    "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "        full_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    # DataLoader configuration\n",
    "    loader_kwargs = {\n",
    "        'batch_size': batch_size,\n",
    "        'num_workers': num_workers,\n",
    "        'pin_memory': True,\n",
    "    }\n",
    "    \n",
    "    if num_workers > 0:\n",
    "        loader_kwargs['persistent_workers'] = persistent_workers\n",
    "        if prefetch_factor is not None:\n",
    "            loader_kwargs['prefetch_factor'] = prefetch_factor\n",
    "        if torch.cuda.is_available():\n",
    "            loader_kwargs['pin_memory_device'] = 'cuda'\n",
    "    \n",
    "    # Create loaders\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_kwargs)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, **loader_kwargs)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=False, **loader_kwargs)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "print(\"Dataset classes defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974b68d",
   "metadata": {},
   "source": [
    "## 5. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2179d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetMalwareDetector(nn.Module):\n",
    "    \"\"\"ResNet-based malware detector for binary classification.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model_name: str = 'resnet18', \n",
    "        num_classes: int = 2, \n",
    "        pretrained: bool = True, \n",
    "        freeze_backbone: bool = False\n",
    "    ):\n",
    "        super(ResNetMalwareDetector, self).__init__()\n",
    "        \n",
    "        # Load backbone\n",
    "        if model_name == 'resnet18':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "            else:\n",
    "                self.backbone = models.resnet18(weights=None)\n",
    "            num_features = 512\n",
    "        elif model_name == 'resnet50':\n",
    "            if pretrained:\n",
    "                self.backbone = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "            else:\n",
    "                self.backbone = models.resnet50(weights=None)\n",
    "            num_features = 2048\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}. Choose 'resnet18' or 'resnet50'\")\n",
    "        \n",
    "        # Optionally freeze backbone\n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace final layer for binary classification\n",
    "        self.backbone.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count trainable parameters in the model.\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# Test model creation\n",
    "print(\"Testing model creation...\")\n",
    "test_model = ResNetMalwareDetector(RESNET_VARIANT, num_classes=2, pretrained=PRETRAINED)\n",
    "print(f\"Model: {RESNET_VARIANT}\")\n",
    "print(f\"Trainable parameters: {count_parameters(test_model):,}\")\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "y = test_model(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {y.shape}\")\n",
    "del test_model, x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca99b1",
   "metadata": {},
   "source": [
    "## 6. Metrics Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsTracker:\n",
    "    \"\"\"Track predictions and compute metrics.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.y_true = []\n",
    "        self.y_pred = []\n",
    "        self.y_scores = []\n",
    "    \n",
    "    def update(self, labels, predictions, scores):\n",
    "        self.y_true.extend(labels.cpu().numpy().tolist())\n",
    "        self.y_pred.extend(predictions.cpu().numpy().tolist())\n",
    "        # Use softmax probabilities for the positive class (Malware)\n",
    "        probs = torch.softmax(scores, dim=1)[:, 1]\n",
    "        self.y_scores.extend(probs.cpu().numpy().tolist())\n",
    "    \n",
    "    def compute_metrics(self) -> Dict[str, float]:\n",
    "        y_true = np.array(self.y_true)\n",
    "        y_pred = np.array(self.y_pred)\n",
    "        y_scores = np.array(self.y_scores)\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        }\n",
    "        \n",
    "        # ROC AUC\n",
    "        if len(np.unique(y_true)) > 1:\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "            metrics['auc'] = auc(fpr, tpr)\n",
    "            metrics['fpr'] = fpr\n",
    "            metrics['tpr'] = tpr\n",
    "        else:\n",
    "            metrics['auc'] = 0.0\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        metrics['confusion_matrix'] = cm\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "\n",
    "print(\"MetricsTracker defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e414e",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d88cfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    scaler: Optional[torch.amp.GradScaler] = None,\n",
    "    gradient_accumulation_steps: int = 1\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "    for batch_idx, (images, labels) in enumerate(pbar):\n",
    "        images = images.to(device, non_blocking=True) \n",
    "        labels = labels.to(device, non_blocking=True).long() \n",
    "        \n",
    "        # Forward pass with optional AMP\n",
    "        with torch.autocast(device_type='cuda', dtype=torch.bfloat16, enabled=(scaler is not None)):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        # Backward pass\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "        \n",
    "        # Track metrics\n",
    "        running_loss += loss.item() * images.size(0) * gradient_accumulation_steps\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item() * gradient_accumulation_steps})\n",
    "    \n",
    "    avg_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    data_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, Dict[str, float]]:\n",
    "    \"\"\"Evaluate model on a dataset.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    metrics_tracker = MetricsTracker()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(data_loader, desc=\"Evaluating\", leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "            metrics_tracker.update(labels, predictions, outputs)\n",
    "    \n",
    "    avg_loss = running_loss / len(data_loader.dataset)\n",
    "    metrics = metrics_tracker.compute_metrics()\n",
    "    \n",
    "    return avg_loss, metrics\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac900fab",
   "metadata": {},
   "source": [
    "## 8. Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617db8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 50,\n",
    "    learning_rate: float = 0.001,\n",
    "    device: torch.device = None,\n",
    "    save_path: Optional[str] = None,\n",
    "    patience: int = 10,\n",
    "    use_amp: bool = True,\n",
    "    gradient_accumulation_steps: int = 1\n",
    ") -> Dict:\n",
    "    \"\"\"Full training loop with early stopping.\"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    print(f\"Training on device: {device}\")\n",
    "    \n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Optional: AMP scaler\n",
    "    scaler = torch.amp.GradScaler('cuda') if use_amp and torch.cuda.is_available() else None\n",
    "    \n",
    "    # History tracking\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'val_auc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    print(f\"\\nStarting training for {num_epochs} epochs...\")\n",
    "    print(f\"Early stopping patience: {patience}\")\n",
    "    print(f\"AMP enabled: {scaler is not None}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device,\n",
    "            scaler=scaler, gradient_accumulation_steps=gradient_accumulation_steps\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_loss, val_metrics = evaluate(model, val_loader, criterion, device)\n",
    "        val_acc = val_metrics['accuracy']\n",
    "        val_auc = val_metrics.get('auc', 0.0)\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # Print progress\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] ({epoch_time:.1f}s)\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict().copy()\n",
    "            print(f\"  -> New best validation loss!\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "        \n",
    "        print()\n",
    "    \n",
    "    # Load best model\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        print(\"Loaded best model from training\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if save_path:\n",
    "        torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'history': history\n",
    "        }, save_path)\n",
    "        print(f\"Model saved to {save_path}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "print(\"Main training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c674c5",
   "metadata": {},
   "source": [
    "## 9. Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "    model: nn.Module,\n",
    "    test_loader: DataLoader,\n",
    "    device: torch.device = None\n",
    ") -> Dict:\n",
    "    \"\"\"Evaluate model on test set and print detailed results.\"\"\"\n",
    "    \n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EVALUATING ON TEST SET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    test_loss, metrics = evaluate(model, test_loader, criterion, device)\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    print(f\"  Test Loss:      {test_loss:.4f}\")\n",
    "    print(f\"  Accuracy:       {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)\")\n",
    "    print(f\"  Precision:      {metrics['precision']:.4f}\")\n",
    "    print(f\"  Recall:         {metrics['recall']:.4f}\")\n",
    "    print(f\"  F1-Score:       {metrics['f1']:.4f}\")\n",
    "    print(f\"  AUC:            {metrics.get('auc', 0):.4f}\")\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    cm = metrics['confusion_matrix']\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"               Predicted\")\n",
    "    print(f\"             Benign  Malware\")\n",
    "    print(f\"  Actual Benign   {cm[0,0]:5d}    {cm[0,1]:5d}\")\n",
    "    print(f\"         Malware  {cm[1,0]:5d}    {cm[1,1]:5d}\")\n",
    "    \n",
    "    metrics['test_loss'] = test_loss\n",
    "    return metrics\n",
    "\n",
    "\n",
    "print(\"Test function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d76ee6",
   "metadata": {},
   "source": [
    "## 10. Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history: Dict, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot training metrics over epochs.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)\n",
    "    axes[1].plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # AUC plot\n",
    "    axes[2].plot(epochs, history['val_auc'], 'g-', label='Val AUC', linewidth=2)\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('AUC')\n",
    "    axes[2].set_title('Validation AUC')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Training history plot saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(metrics: Dict, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot ROC curve.\"\"\"\n",
    "    if 'fpr' not in metrics or 'tpr' not in metrics:\n",
    "        print(\"ROC curve data not available\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(metrics['fpr'], metrics['tpr'], 'b-', linewidth=2, \n",
    "             label=f'ROC curve (AUC = {metrics[\"auc\"]:.4f})')\n",
    "    plt.plot([0, 1], [0, 1], 'r--', linewidth=1, label='Random classifier')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"ROC curve saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm: np.ndarray, save_path: Optional[str] = None):\n",
    "    \"\"\"Plot confusion matrix.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap='Blues')\n",
    "    plt.title('Confusion Matrix', fontsize=14)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    classes = ['Benign', 'Malware']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, fontsize=12)\n",
    "    plt.yticks(tick_marks, classes, fontsize=12)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\",\n",
    "                    fontsize=20)\n",
    "    \n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Confusion matrix saved to {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_sample_images(data_loader: DataLoader, num_samples: int = 4):\n",
    "    \"\"\"Visualize sample images from the dataset.\"\"\"\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 3*num_samples))\n",
    "    channel_names = ['Bigram Frequency', 'DCT Transform', 'Byteplot']\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        label = \"Malware\" if labels[i] == 1 else \"Benign\"\n",
    "        \n",
    "        for j in range(3):\n",
    "            axes[i, j].imshow(images[i, j].numpy(), cmap='viridis')\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(channel_names[j])\n",
    "            axes[i, j].axis('off')\n",
    "        \n",
    "        axes[i, 0].set_ylabel(label, fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367dff05",
   "metadata": {},
   "source": [
    "## 11. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd6b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    data_dir=DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_split=TRAIN_SPLIT,\n",
    "    val_split=VAL_SPLIT,\n",
    "    test_split=TEST_SPLIT,\n",
    "    max_samples=MAX_SAMPLES,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    prefetch_factor=PREFETCH_FACTOR,\n",
    "    persistent_workers=PERSISTENT_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"\\nBatch size: {BATCH_SIZE}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b762d19",
   "metadata": {},
   "source": [
    "## 12. Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c421e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from the training set\n",
    "visualize_sample_images(train_loader, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5028488c",
   "metadata": {},
   "source": [
    "## 13. Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb22b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = ResNetMalwareDetector(\n",
    "    model_name=RESNET_VARIANT,\n",
    "    num_classes=2,\n",
    "    pretrained=PRETRAINED,\n",
    "    freeze_backbone=FREEZE_BACKBONE\n",
    ")\n",
    "\n",
    "print(f\"Model: {RESNET_VARIANT}\")\n",
    "print(f\"Pretrained: {PRETRAINED}\")\n",
    "print(f\"Freeze backbone: {FREEZE_BACKBONE}\")\n",
    "print(f\"Trainable parameters: {count_parameters(model):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb85bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "save_path = os.path.join(CHECKPOINT_DIR, 'resnet_best.pth')\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=DEVICE,\n",
    "    save_path=save_path,\n",
    "    patience=PATIENCE,\n",
    "    use_amp=USE_AMP,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b4f57",
   "metadata": {},
   "source": [
    "## 14. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25b550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(\n",
    "    history, \n",
    "    save_path=os.path.join(RESULTS_DIR, 'training_history.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e99df3",
   "metadata": {},
   "source": [
    "## 15. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62825d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_metrics = test_model(model, test_loader, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0a335",
   "metadata": {},
   "source": [
    "## 16. Plot ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d0808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve\n",
    "plot_roc_curve(\n",
    "    test_metrics, \n",
    "    save_path=os.path.join(RESULTS_DIR, 'roc_curve.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c137955f",
   "metadata": {},
   "source": [
    "## 17. Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbd4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(\n",
    "    test_metrics['confusion_matrix'], \n",
    "    save_path=os.path.join(RESULTS_DIR, 'confusion_matrix.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be9f9b",
   "metadata": {},
   "source": [
    "## 18. Load Saved Model (Optional)\n",
    "\n",
    "Use this section to load a previously trained model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fea764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model checkpoint\n",
    "def load_model(checkpoint_path: str, model_name: str = 'resnet50'):\n",
    "    \"\"\"Load a saved model from checkpoint.\"\"\"\n",
    "    model = ResNetMalwareDetector(\n",
    "        model_name=model_name,\n",
    "        num_classes=2,\n",
    "        pretrained=False\n",
    "    )\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"Model loaded from {checkpoint_path}\")\n",
    "    return model, checkpoint.get('history', None)\n",
    "\n",
    "\n",
    "# Uncomment to load a saved model:\n",
    "# loaded_model, saved_history = load_model(\n",
    "#     os.path.join(CHECKPOINT_DIR, 'resnet_best.pth'),\n",
    "#     model_name=RESNET_VARIANT\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07908b7a",
   "metadata": {},
   "source": [
    "## 19. Single File Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd9d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_file(model: nn.Module, file_path: str, device: torch.device = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Predict whether a single file is malware or benign.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with prediction, confidence scores, and label\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Generate image from file\n",
    "    image = create_three_channel_image(file_path)\n",
    "    image_tensor = torch.from_numpy(image).float().unsqueeze(0).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)[0]\n",
    "        prediction = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    result = {\n",
    "        'file': file_path,\n",
    "        'prediction': 'Malware' if prediction == 1 else 'Benign',\n",
    "        'prediction_class': prediction,\n",
    "        'confidence_benign': probabilities[0].item(),\n",
    "        'confidence_malware': probabilities[1].item(),\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# result = predict_file(model, '../data/benign/sample.exe', device=DEVICE)\n",
    "# print(f\"File: {result['file']}\")\n",
    "# print(f\"Prediction: {result['prediction']}\")\n",
    "# print(f\"Confidence - Benign: {result['confidence_benign']:.4f}\")\n",
    "# print(f\"Confidence - Malware: {result['confidence_malware']:.4f}\")\n",
    "\n",
    "print(\"Single file prediction function defined!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
